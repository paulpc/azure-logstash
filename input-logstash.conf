input {
    tcp {
        port => 5514
        codec => json
        ssl_enable => true
        ssl_cert => "/etc/logstash/logstash.cer"
        ssl_key => "/etc/logstash/logstash.key"
        ssl_verify => false
        ssl_extra_chain_certs => ["/etc/logstash/syslog-tls.cert"]
    }
    tcp {
        port => 6514
        ssl_enable => true
        ssl_cert => "/etc/logstash/logstash.cer"
        ssl_key => "/etc/logstash/logstash.key"
        ssl_verify => false
        ssl_extra_chain_certs => ["/etc/logstash/syslog-tls.cert"]
         add_field => {
        "[fields][logsource]" => "syslog1(please replace me)"
        }
    }
    tcp {
        port => 6515
        ssl_enable => true
        ssl_cert => "/etc/logstash/logstash.cer"
        ssl_key => "/etc/logstash/logstash.key"
        ssl_verify => false
        ssl_extra_chain_certs => ["/etc/logstash/syslog-tls.cert"]
        # using the [fields][logsource] field for selecting the message pipeline
         add_field => {
            "[fields][logsource]" => "syslog2(please replace me)"
        }
    }
    beats {
        port => 5044
        ssl => true
        ssl_certificate_authorities => ["/etc/logstash/root.pem","/etc/logstash/issuing.pem"]
        ssl_certificate => "/etc/logstash/logstash.cer"
        ssl_key => "/etc/logstash/logstash.p8"
        ssl_verify_mode => "force_peer"
  }
}

filter {
    if [fields][logsource] == "activeDirectory" {
        if [event_data][TargetUserName] {
            mutate {
                add_field => {
                    "username" => "%{[event_data][TargetUserName]}"
                }
            }
        } else if [event_data][SubjectUserName] {
            mutate {
                add_field => {
                    "username" => "%{[event_data][SubjectUserName]}"
                }
            }
        }
        if [event_data][DestAddress] {
            mutate {
                add_field => {
                    "dst_ipv4" => "%{[event_data][DestAddress]}"
                    }
                }
        }
        if [event_data][SourceAddress] {
            mutate {
                add_field => {
                    "src_ipv4" => "%{[event_data][SourceAddress]}"
                    }
                }
        }
        if [event_data][DestPort] {
            mutate {
                add_field => {
                    "dst_port" => "%{[event_data][DestPort]}"
                    }
                }
        }
        if [event_data][SourcePort] {
            mutate {
                add_field => {
                    "src_port" => "%{[event_data][SourcePort]}"
                    }
                }
            }
    }
    else if [fields][logsource] == "IIS" {
        grok {
            ## Very helpful site for building these statements:
            #   http://grokdebug.herokuapp.com/
            # This is configured to parse out every field of IIS's W3C format when
            #   every field is included in the logs
            match => ["message", "%{TIMESTAMP_ISO8601:log_timestamp} %{WORD:serviceName} %{WORD:serverName} %{IP:dst_ipv4} %{WORD:method} %{URIPATH:uriStem} %{NOTSPACE:uriQuery} %{NUMBER:dst_port} %{NOTSPACE:username} %{IPORHOST:src_ip4} %{NOTSPACE:protocolVersion} %{NOTSPACE:userAgent} %{NOTSPACE:cookie} %{NOTSPACE:referer} %{NOTSPACE:requestHost} %{NUMBER:response} %{NUMBER:subresponse} %{NUMBER:win32response} %{NUMBER:bytesSent} %{NUMBER:bytesReceived} %{NUMBER:timetaken}"]
        }

        mutate {
            ## Convert some fields from strings to integers
            convert => ["bytesSent", "integer"]
            convert => ["bytesReceived", "integer"]
            convert => ["timetaken", "integer"]
            split => {"log_timestamp" =>  " "}
            add_field => {
            "date" => "%{log_timestamp[0]}"
            }

            ## Finally remove the original log_timestamp field since the event will
            #   have the proper date on it
            remove_field => [ "log_timestamp"]
        }

        ## Set the Event Timestamp from the log
        #
        date {
            match => [ "log_timestamp", "YYYY-MM-dd HH:mm:ss" ]
            timezone => "CST6CDT"
        }

        useragent {
                source=> "userAgent"
                prefix=> "browser"
            }
    }
}

output {
    # i reccommend having a topic per message action type and an if statement here for differentiating between pipelines
    kafka {
            codec => json
            topic_id => "logstash_incoming"
            bootstrap_servers => "kafka-bootstrap-1.internal.cloudapp.net:9092,kafka-bootstrap-2.internal.cloudapp.net:9092,kafka-bootstrap-3.internal.cloudapp.net:9092"
        }
    
}
